

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Azure Data Factory Templates &mdash; NHSX Data Engineering 0.0.2 documentation</title>
  

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/theme_overrides.css" type="text/css" />

  
  
    <link rel="shortcut icon" href="_static/favicon.png"/>
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/language_data.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Azure Data Factory Utilities" href="adfutilities.html" />
    <link rel="prev" title="Azure Platform Overview" href="readme.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: #2980B9" >
          

          
            <a href="index.html" class="icon icon-home"> NHSX Data Engineering
          

          
            
            <img src="_static/logo-wordmark-light.svg" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                0.0.2
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Core Products</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="nhsappanalytics.html">NHS App Analytics Dashboard</a></li>
</ul>
<p class="caption"><span class="caption-text">Data Engineering</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="readme.html">Azure Platform Overview</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Azure Data Factory Templates</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#sql-database-ingestion-pipeline">SQL Database Ingestion Pipeline</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#metadata">Metadata</a></li>
<li class="toctree-l3"><a class="reference internal" href="#description">Description</a></li>
<li class="toctree-l3"><a class="reference internal" href="#pipeline-configuration">Pipeline Configuration</a></li>
<li class="toctree-l3"><a class="reference internal" href="#data-factory-configuration">Data Factory Configuration</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#databricks-ingestion-pipeline">Databricks Ingestion Pipeline</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id1">Metadata</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id2">Description</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id3">Pipeline Configuration</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id4">Data Factory Configuration</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#excel-sheet-ingestion-pipeline">Excel Sheet Ingestion Pipeline</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id5">Metadata</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id6">Description</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id7">Pipeline Configuration</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id8">Data Factory Configuration</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#multiple-excel-sheet-ingestion-pipeline">Multiple Excel Sheet Ingestion Pipeline</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id9">Metadata</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id10">Description</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id11">Pipeline Configuration</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id12">Data Factory Configuration</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#web-url-data-ingestion-pipeline">Web URL Data Ingestion Pipeline</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id13">Metadata</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id14">Description</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id15">Pipeline Configuration</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id16">Data Factory Configuration</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#azure-function-app-ingestion-pipeline">Azure Function App Ingestion Pipeline</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id17">Metadata</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id18">Description</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id19">Pipeline Configuration</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id20">Data Factory Configuration</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#sharepoint-ingestion-pipeline">SharePoint Ingestion Pipeline</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id21">Metadata</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id22">Description</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id23">Pipeline Configuration</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id24">Data Factory Configuration</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#databricks-processing-pipeline">Databricks Processing Pipeline</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id25">Metadata</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id26">Description</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id27">Pipeline Configuration</a></li>
<li class="toctree-l3"><a class="reference internal" href="#databricks-orchestration">Databricks Orchestration</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id28">Data Factory Configuration</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#azure-function-app-processing-pipeline">Azure Function App Processing Pipeline</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id29">Metadata</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id30">Description</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id31">Pipeline Configuration</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id32">Data Factory Configuration</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#multiple-azure-function-apps-processing-pipeline">Multiple Azure Function Apps Processing Pipeline</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id33">Metadata</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id34">Description</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id35">Pipeline Configuration</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id36">Data Factory Configuration</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#copy-file-processing-pipeline">Copy File Processing Pipeline</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id37">Metadata</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id38">Description</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id39">Pipeline Configuration</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id40">Data Factory Configuration</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#sql-table-staging-pipeline">SQL Table Staging Pipeline</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id41">Metadata</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id42">Description</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id43">Pipeline Configuration</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id44">Data Factory Configuration</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#multiple-sql-table-staging-pipeline">Multiple SQL Table Staging Pipeline</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id45">Metadata</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id46">Description</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id47">Pipeline Configuration</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id48">Data Factory Configuration</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="adfutilities.html">Azure Data Factory Utilities</a></li>
<li class="toctree-l1"><a class="reference internal" href="databricksfunc.html">Azure Databricks Functions</a></li>
</ul>
<p class="caption"><span class="caption-text">Open Analytics</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="openanalyticstemplate.html">Open Analytics Template</a></li>
</ul>
<p class="caption"><span class="caption-text">Appendix</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="changelog.html">Changelog</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">NHSX Data Engineering</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Azure Data Factory Templates</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="_sources/adfpipelines.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="azure-data-factory-templates">
<h1>Azure Data Factory Templates<a class="headerlink" href="#azure-data-factory-templates" title="Permalink to this headline">¶</a></h1>
<p>Open access and reusable design documentation of pipelines used in the NHSX Analytics Unit Azure Data Factory (ADF) environment.</p>
<div class="section" id="sql-database-ingestion-pipeline">
<h2>SQL Database Ingestion Pipeline<a class="headerlink" href="#sql-database-ingestion-pipeline" title="Permalink to this headline">¶</a></h2>
<div class="section" id="metadata">
<h3>Metadata<a class="headerlink" href="#metadata" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># -------------------------------------------------------------------------</span>
<span class="c1"># Copyright (c) 2021 NHS England and NHS Improvement. All rights reserved.</span>
<span class="c1"># Licensed under the MIT License. See license.txt in the project root for</span>
<span class="c1"># license information.</span>
<span class="c1"># -------------------------------------------------------------------------</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">FILE:           ingestion_sql.json</span>
<span class="sd">DESCRIPTION:</span>
<span class="sd">                Pipeline to ingest raw data to Azure Datalake blob storage</span>
<span class="sd">                from a SQL database.</span>

<span class="sd">CONTRIBUTORS:   Craig Shenton, Mattia Ficarelli</span>
<span class="sd">CONTACT:        data@nhsx.nhs.uk</span>
<span class="sd">CREATED:        20 Sept 2021</span>
<span class="sd">VERSION:        0.0.1</span>
<span class="sd">&quot;&quot;&quot;</span>
</pre></div>
</div>
</div>
<div class="section" id="description">
<h3>Description<a class="headerlink" href="#description" title="Permalink to this headline">¶</a></h3>
<a class="reference internal image-reference" href="_images/sql-ingest.png"><img alt="Data ingestion from a SQL database" src="_images/sql-ingest.png" style="width: 600px;" /></a>
<p><em>Figure 1: Data ingestion from a SQL database</em></p>
<p>Pipeline to ingest raw data to Azure Datalake blob storage from a SQL database.</p>
<blockquote>
<div><ol class="arabic simple">
<li><p>Looks up the <code class="docutils literal notranslate"><span class="pre">.json</span></code> configuration file for this pipeline</p></li>
<li><p>Source:</p>
<ol class="loweralpha simple">
<li><p>Sets the source database owner (dbo)</p></li>
<li><p>Sets the source table</p></li>
<li><p>Sets the SQL query</p></li>
</ol>
</li>
<li><p>Sink:</p>
<ol class="loweralpha simple">
<li><p>Sets the file system</p></li>
<li><p>Sets the sink path</p></li>
<li><p>Sets the sink file</p></li>
</ol>
</li>
<li><p>Copy activity copies the data returned from the SQL query as either a <code class="docutils literal notranslate"><span class="pre">.csv</span></code> file or a <code class="docutils literal notranslate"><span class="pre">.parquet</span></code> file.</p></li>
<li><p>If the copy activity fails, the error notification logic app API will notify the specified email address of the error</p></li>
</ol>
</div></blockquote>
</div>
<div class="section" id="pipeline-configuration">
<h3>Pipeline Configuration<a class="headerlink" href="#pipeline-configuration" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
  <span class="s2">&quot;pipeline&quot;</span><span class="p">:</span> <span class="p">{</span>
    <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;ingestion_sql&quot;</span><span class="p">,</span>
    <span class="s2">&quot;folder&quot;</span><span class="p">:</span> <span class="s2">&quot;templates/ingestion/sql&quot;</span><span class="p">,</span>
    <span class="s2">&quot;adl_file_system&quot;</span><span class="p">:</span> <span class="s2">&quot;file_system&quot;</span><span class="p">,</span>
    <span class="s2">&quot;raw&quot;</span><span class="p">:</span> <span class="p">{</span>
      <span class="s2">&quot;source_dbo&quot;</span><span class="p">:</span> <span class="s2">&quot;dbo&quot;</span><span class="p">,</span>
      <span class="s2">&quot;source_table&quot;</span><span class="p">:</span> <span class="s2">&quot;table_1&quot;</span><span class="p">,</span>
      <span class="s2">&quot;source_query&quot;</span><span class="p">:</span> <span class="s2">&quot;SELECT * FROM dbo.table_1 ORDER BY Date DESC&quot;</span><span class="p">,</span>
      <span class="s2">&quot;sink_path&quot;</span><span class="p">:</span> <span class="s2">&quot;raw/path/to/data&quot;</span><span class="p">,</span>
      <span class="s2">&quot;sink_file&quot;</span><span class="p">:</span> <span class="s2">&quot;table_1.parquet&quot;</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="data-factory-configuration">
<h3>Data Factory Configuration<a class="headerlink" href="#data-factory-configuration" title="Permalink to this headline">¶</a></h3>
<p>Download the Azure Data Factory json configuration file to use this template in your own data pipelines.</p>
<p><a class="reference download external" download="" href="https://raw.githubusercontent.com/nhsx/au-data-engineering/main/config-files/adf-templates/sql-ingestion.json"><code class="xref download docutils literal notranslate"><span class="pre">sql-ingestion.json</span></code></a></p>
</div>
</div>
<div class="section" id="databricks-ingestion-pipeline">
<h2>Databricks Ingestion Pipeline<a class="headerlink" href="#databricks-ingestion-pipeline" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id1">
<h3>Metadata<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># -------------------------------------------------------------------------</span>
<span class="c1"># Copyright (c) 2021 NHS England and NHS Improvement. All rights reserved.</span>
<span class="c1"># Licensed under the MIT License. See license.txt in the project root for</span>
<span class="c1"># license information.</span>
<span class="c1"># -------------------------------------------------------------------------</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">FILE:           ingestion_databricks.json</span>
<span class="sd">DESCRIPTION:</span>
<span class="sd">                Pipeline to ingest raw data to Azure Datalake blob storage</span>
<span class="sd">                using a databricks notebook.</span>

<span class="sd">CONTRIBUTORS:   Craig Shenton, Mattia Ficarelli</span>
<span class="sd">CONTACT:        data@nhsx.nhs.uk</span>
<span class="sd">CREATED:        20 Sept 2021</span>
<span class="sd">VERSION:        0.0.1</span>
<span class="sd">&quot;&quot;&quot;</span>
</pre></div>
</div>
</div>
<div class="section" id="id2">
<h3>Description<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h3>
<a class="reference internal image-reference" href="_images/databricks.png"><img alt="Data ingestion using a databricks notebook" src="_images/databricks.png" style="width: 600px;" /></a>
<p><em>Figure 1: Data ingestion using a databricks notebook</em></p>
<p>Pipeline to ingest raw data to Azure Datalake blob storage using a databricks notebook.</p>
<blockquote>
<div><ol class="arabic simple">
<li><p>Lookup the <code class="docutils literal notranslate"><span class="pre">.json</span></code> configuration file for this pipeline.</p></li>
<li><p>Set the databricks notebook path.</p></li>
<li><p>Databricks notebook activity runs the databricks notebook specified using an ephemeral job cluster.</p></li>
<li><p>If the databricks notebook activity fails, the error notification logic app API will notify the specified email address of the error.</p></li>
</ol>
</div></blockquote>
<p>Within the databricks notebook, using Azure Databricks Functions, data can be saved to blob storage as either a <code class="docutils literal notranslate"><span class="pre">.csv</span></code> file or a <code class="docutils literal notranslate"><span class="pre">.parquet</span></code> file.</p>
</div>
<div class="section" id="id3">
<h3>Pipeline Configuration<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
  <span class="s2">&quot;pipeline&quot;</span><span class="p">:</span> <span class="p">{</span>
    <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;ingestion_databricks&quot;</span><span class="p">,</span>
    <span class="s2">&quot;folder&quot;</span><span class="p">:</span> <span class="s2">&quot;templates/ingestion/databricks&quot;</span><span class="p">,</span>
    <span class="s2">&quot;adl_file_system&quot;</span><span class="p">:</span> <span class="s2">&quot;file_system&quot;</span><span class="p">,</span>
    <span class="s2">&quot;raw&quot;</span><span class="p">:</span> <span class="p">{</span>
      <span class="s2">&quot;databricks_notebook&quot;</span><span class="p">:</span> <span class="s2">&quot;/path/to/databricks/notebook&quot;</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="id4">
<h3>Data Factory Configuration<a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h3>
<p>Download the Azure Data Factory <code class="docutils literal notranslate"><span class="pre">.json</span></code> configuration file to use this template in your own data pipelines.</p>
<p><a class="reference download external" download="" href="https://raw.githubusercontent.com/nhsx/au-data-engineering/main/config-files/adf-templates/databricks-ingestion.json"><code class="xref download docutils literal notranslate"><span class="pre">databricks-ingestion.json</span></code></a></p>
</div>
</div>
<div class="section" id="excel-sheet-ingestion-pipeline">
<h2>Excel Sheet Ingestion Pipeline<a class="headerlink" href="#excel-sheet-ingestion-pipeline" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id5">
<h3>Metadata<a class="headerlink" href="#id5" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># -------------------------------------------------------------------------</span>
<span class="c1"># Copyright (c) 2021 NHS England and NHS Improvement. All rights reserved.</span>
<span class="c1"># Licensed under the MIT License. See license.txt in the project root for</span>
<span class="c1"># license information.</span>
<span class="c1"># -------------------------------------------------------------------------</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">FILE:           ingestion_excel_sheet.json</span>
<span class="sd">DESCRIPTION:</span>
<span class="sd">                Pipeline to ingest a specified excel file sheet, as a .csv</span>
<span class="sd">                file, to Azure Datalake blob storage.</span>

<span class="sd">CONTRIBUTORS:   Craig Shenton, Mattia Ficarelli</span>
<span class="sd">CONTACT:        data@nhsx.nhs.uk</span>
<span class="sd">CREATED:        20 Sept 2021</span>
<span class="sd">VERSION:        0.0.1</span>
<span class="sd">&quot;&quot;&quot;</span>
</pre></div>
</div>
</div>
<div class="section" id="id6">
<h3>Description<a class="headerlink" href="#id6" title="Permalink to this headline">¶</a></h3>
<a class="reference internal image-reference" href="_images/excel_sheet_ingestion.png"><img alt="Data ingestion of an excel file sheet" src="_images/excel_sheet_ingestion.png" style="width: 600px;" /></a>
<p><em>Figure 1: Data ingestion of an excel file sheet</em></p>
<p>Pipeline to ingest a specified excel file sheet, as a <code class="docutils literal notranslate"><span class="pre">.csv</span></code> file, to Azure Datalake blob storage.</p>
<blockquote>
<div><ol class="arabic simple">
<li><p>Lookup the <code class="docutils literal notranslate"><span class="pre">.json</span></code> configuration file for this pipeline.</p></li>
<li><p>Set the Azure Datalake file system.</p></li>
<li><p>Set the source file path, file name, and excel sheet name.</p></li>
<li><p>Set the sink file path and file name.</p></li>
<li><p>Copy activity ingests the excel sheet data to a <code class="docutils literal notranslate"><span class="pre">.csv</span></code> file.</p></li>
<li><p>If the copy activity fails, the error notification logic app API will notify the specified email address of the error.</p></li>
</ol>
</div></blockquote>
</div>
<div class="section" id="id7">
<h3>Pipeline Configuration<a class="headerlink" href="#id7" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
  <span class="s2">&quot;pipeline&quot;</span><span class="p">:</span> <span class="p">{</span>
    <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;ingestion_excel_sheet&quot;</span><span class="p">,</span>
    <span class="s2">&quot;folder&quot;</span><span class="p">:</span> <span class="s2">&quot;templates/ingestion/excel_sheet&quot;</span><span class="p">,</span>
    <span class="s2">&quot;adl_file_system&quot;</span><span class="p">:</span> <span class="s2">&quot;file_system&quot;</span><span class="p">,</span>
    <span class="s2">&quot;raw&quot;</span><span class="p">:</span> <span class="p">{</span>
      <span class="s2">&quot;source_path&quot;</span><span class="p">:</span> <span class="s2">&quot;raw/&quot;</span><span class="p">,</span>
      <span class="s2">&quot;source_file&quot;</span><span class="p">:</span> <span class="s2">&quot;file.xlsx&quot;</span><span class="p">,</span>
      <span class="s2">&quot;source_sheet&quot;</span><span class="p">:</span> <span class="s2">&quot;table_1&quot;</span><span class="p">,</span>
      <span class="s2">&quot;sink_path&quot;</span><span class="p">:</span> <span class="s2">&quot;processed/&quot;</span><span class="p">,</span>
      <span class="s2">&quot;sink_name&quot;</span><span class="p">:</span> <span class="s2">&quot;table_1.csv&quot;</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="id8">
<h3>Data Factory Configuration<a class="headerlink" href="#id8" title="Permalink to this headline">¶</a></h3>
<p>Download the Azure Data Factory <code class="docutils literal notranslate"><span class="pre">.json</span></code> configuration file to use this template in your own data pipelines.
<a class="reference download external" download="" href="https://raw.githubusercontent.com/nhsx/au-data-engineering/main/config-files/adf-templates/excel-sheet-ingestion.json"><code class="xref download docutils literal notranslate"><span class="pre">excel-sheet-ingestion.json</span></code></a></p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Alternatively this a variation of this pipeline can be used to ingest multiple excel file sheets to a set of <cite>.csv</cite> files in Azure Datalake blob storage.</p>
</div>
</div>
</div>
<div class="section" id="multiple-excel-sheet-ingestion-pipeline">
<h2>Multiple Excel Sheet Ingestion Pipeline<a class="headerlink" href="#multiple-excel-sheet-ingestion-pipeline" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id9">
<h3>Metadata<a class="headerlink" href="#id9" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># -------------------------------------------------------------------------</span>
<span class="c1"># Copyright (c) 2021 NHS England and NHS Improvement. All rights reserved.</span>
<span class="c1"># Licensed under the MIT License. See license.txt in the project root for</span>
<span class="c1"># license information.</span>
<span class="c1"># -------------------------------------------------------------------------</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">FILE:           ingestion_multiple_excel_sheets.json</span>
<span class="sd">DESCRIPTION:</span>
<span class="sd">                Pipeline to ingest multiple specified excel file sheets as .csv files</span>
<span class="sd">                to Azure Datalake blob storage.</span>

<span class="sd">CONTRIBUTORS:   Craig Shenton, Mattia Ficarelli</span>
<span class="sd">CONTACT:        data@nhsx.nhs.uk</span>
<span class="sd">CREATED:        20 Sept 2021</span>
<span class="sd">VERSION:        0.0.1</span>
<span class="sd">&quot;&quot;&quot;</span>
</pre></div>
</div>
</div>
<div class="section" id="id10">
<h3>Description<a class="headerlink" href="#id10" title="Permalink to this headline">¶</a></h3>
<a class="reference internal image-reference" href="_images/multiple_excel_sheet_ingestion.png"><img alt="Data ingestion of multiple excel file sheets" src="_images/multiple_excel_sheet_ingestion.png" style="width: 600px;" /></a>
<p><em>Figure 1: Data ingestion of multiple excel file sheets</em></p>
<a class="reference internal image-reference" href="_images/multiple_excel_sheet_ingestion_2.png"><img alt="ForEach loop activities within pipeline" src="_images/multiple_excel_sheet_ingestion_2.png" style="width: 600px;" /></a>
<p><em>Figure 2: ForEach loop activities within pipeline</em></p>
<p>Pipeline to ingest multiple specified excel file sheets as <code class="docutils literal notranslate"><span class="pre">.csv</span></code> files to Azure Datalake blob storage.</p>
<blockquote>
<div><ol class="arabic simple">
<li><p>Looks up the <code class="docutils literal notranslate"><span class="pre">.json</span></code> configuration file for this pipeline.</p></li>
<li><p>Set the Azure Datalake file system.</p></li>
<li><p>Set the source path to the folder containing the excel files.</p></li>
<li><p>Set the sink path.</p></li>
<li><p>Set an <cite>array</cite> variable containing the list of excel file metadata.</p></li>
<li><p>ForEach loops over each excel file:</p>
<ol class="loweralpha simple">
<li><p>Sets the source sheet and sink file.</p></li>
<li><p>Copy activity ingests the excel sheet data and saves it as a <code class="docutils literal notranslate"><span class="pre">.csv</span></code> file.</p></li>
<li><p>If the copy activity fails, the error notification logic app API will notify the specified email address of the error.</p></li>
</ol>
</li>
</ol>
</div></blockquote>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Copy activity has ‘File path type’ set to wildcard and the file name regex as <code class="docutils literal notranslate"><span class="pre">*.xlsx</span></code> (excel) (see Figure 3).</p>
</div>
<a class="reference internal image-reference" href="_images/multiple_excel_sheet_ingestion_3.png"><img alt="Copy activity wildcard setup" src="_images/multiple_excel_sheet_ingestion_3.png" style="width: 600px;" /></a>
<p><em>Figure 3: Copy activity wildcard setup</em></p>
</div>
<div class="section" id="id11">
<h3>Pipeline Configuration<a class="headerlink" href="#id11" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
  <span class="s2">&quot;pipeline&quot;</span><span class="p">:</span> <span class="p">{</span>
    <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;ingestion_multiple_excel_sheets&quot;</span><span class="p">,</span>
    <span class="s2">&quot;folder&quot;</span><span class="p">:</span> <span class="s2">&quot;templates/ingestion/multiple_excel_sheets&quot;</span><span class="p">,</span>
    <span class="s2">&quot;adl_file_system&quot;</span><span class="p">:</span> <span class="s2">&quot;file_system&quot;</span><span class="p">,</span>
    <span class="s2">&quot;raw&quot;</span><span class="p">:</span> <span class="p">{</span>
      <span class="s2">&quot;source_path&quot;</span><span class="p">:</span> <span class="s2">&quot;ingestion/&quot;</span><span class="p">,</span>
      <span class="s2">&quot;sink_path&quot;</span><span class="p">:</span> <span class="s2">&quot;raw/path/to/data&quot;</span><span class="p">,</span>
      <span class="s2">&quot;sink_path&quot;</span><span class="p">:</span> <span class="s2">&quot;processed/&quot;</span>
      <span class="s2">&quot;excel&quot;</span><span class="p">:[</span>
    <span class="p">{</span>
      <span class="s2">&quot;sink_file&quot;</span><span class="p">:</span> <span class="s2">&quot;table_1.csv&quot;</span><span class="p">,</span>
      <span class="s2">&quot;source_sheet&quot;</span><span class="p">:</span> <span class="s2">&quot;sheet_1&quot;</span>
    <span class="p">},</span>
    <span class="p">{</span>
      <span class="s2">&quot;sink_file&quot;</span><span class="p">:</span> <span class="s2">&quot;table_2.csv&quot;</span><span class="p">,</span>
      <span class="s2">&quot;source_sheet&quot;</span><span class="p">:</span> <span class="s2">&quot;sheet_2&quot;</span>
    <span class="p">},</span>
    <span class="p">{</span>
      <span class="s2">&quot;sink_file&quot;</span><span class="p">:</span> <span class="s2">&quot;table_3.csv&quot;</span><span class="p">,</span>
      <span class="s2">&quot;source_sheet&quot;</span><span class="p">:</span> <span class="s2">&quot;sheet_3&quot;</span>
    <span class="p">}</span>
  <span class="p">]</span>
<span class="p">}</span>
</pre></div>
</div>
<p>}</p>
</div>
<div class="section" id="id12">
<h3>Data Factory Configuration<a class="headerlink" href="#id12" title="Permalink to this headline">¶</a></h3>
<p>Download the Azure Data Factory <code class="docutils literal notranslate"><span class="pre">.json</span></code> configuration file to use this template in your own data pipelines.</p>
<p><a class="reference download external" download="" href="https://raw.githubusercontent.com/nhsx/au-data-engineering/main/config-files/adf-templates/multiple-excel-sheet-ingestion.json"><code class="xref download docutils literal notranslate"><span class="pre">multiple-excel-sheet-ingestion.json</span></code></a></p>
</div>
</div>
<div class="section" id="web-url-data-ingestion-pipeline">
<h2>Web URL Data Ingestion Pipeline<a class="headerlink" href="#web-url-data-ingestion-pipeline" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id13">
<h3>Metadata<a class="headerlink" href="#id13" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># -------------------------------------------------------------------------</span>
<span class="c1"># Copyright (c) 2021 NHS England and NHS Improvement. All rights reserved.</span>
<span class="c1"># Licensed under the MIT License. See license.txt in the project root for</span>
<span class="c1"># license information.</span>
<span class="c1"># -------------------------------------------------------------------------</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">FILE:           ingestion_web_url.json</span>
<span class="sd">DESCRIPTION:</span>
<span class="sd">                Pipeline to ingest data from a URL as a .csv file to</span>
<span class="sd">                Azure Datalake blob storage.</span>

<span class="sd">CONTRIBUTORS:   Craig Shenton, Mattia Ficarelli</span>
<span class="sd">CONTACT:        data@nhsx.nhs.uk</span>
<span class="sd">CREATED:        20 Sept 2021</span>
<span class="sd">VERSION:        0.0.1</span>
<span class="sd">&quot;&quot;&quot;</span>
</pre></div>
</div>
</div>
<div class="section" id="id14">
<h3>Description<a class="headerlink" href="#id14" title="Permalink to this headline">¶</a></h3>
<a class="reference internal image-reference" href="_images/web_url_ingestion.png"><img alt="Data ingestion from a web URL" src="_images/web_url_ingestion.png" style="width: 600px;" /></a>
<p><em>Figure 1: Data ingestion from a web URL</em></p>
<p>Pipeline to ingest data from a web URL as a <code class="docutils literal notranslate"><span class="pre">.csv</span></code> file to Azure Datalake blob storage.</p>
<blockquote>
<div><ol class="arabic simple">
<li><p>Lookup the <code class="docutils literal notranslate"><span class="pre">.json</span></code> configuration file for this pipeline.</p></li>
<li><p>Set the source URL.</p></li>
<li><p>Set the file system.</p></li>
<li><p>Set the sink path.</p></li>
<li><p>Set the sink file.</p></li>
<li><p>Copy activity copies the data returned from the URL as a <code class="docutils literal notranslate"><span class="pre">.csv</span></code> file.</p></li>
<li><p>If the copy activity fails, the error notification logic app API will notify the specified email address of the error.</p></li>
</ol>
</div></blockquote>
</div>
<div class="section" id="id15">
<h3>Pipeline Configuration<a class="headerlink" href="#id15" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
  <span class="s2">&quot;pipeline&quot;</span><span class="p">:</span> <span class="p">{</span>
    <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;ingestion_web_url&quot;</span><span class="p">,</span>
    <span class="s2">&quot;folder&quot;</span><span class="p">:</span> <span class="s2">&quot;templates/ingestion/web_url&quot;</span><span class="p">,</span>
    <span class="s2">&quot;adl_file_system&quot;</span><span class="p">:</span> <span class="s2">&quot;file_system&quot;</span><span class="p">,</span>
    <span class="s2">&quot;raw&quot;</span><span class="p">:</span> <span class="p">{</span>
      <span class="s2">&quot;source_url&quot;</span><span class="p">:</span> <span class="s2">&quot;https://www.sourcedata.com&quot;</span><span class="p">,</span>
      <span class="s2">&quot;sink_path&quot;</span><span class="p">:</span> <span class="s2">&quot;raw/path/to/data&quot;</span><span class="p">,</span>
      <span class="s2">&quot;sink_file&quot;</span><span class="p">:</span> <span class="s2">&quot;table_1.csv&quot;</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="id16">
<h3>Data Factory Configuration<a class="headerlink" href="#id16" title="Permalink to this headline">¶</a></h3>
<p>Download the Azure Data Factory <code class="docutils literal notranslate"><span class="pre">.json</span></code> configuration file to use this template in your own data pipelines.</p>
<p><a class="reference download external" download="" href="https://raw.githubusercontent.com/nhsx/au-data-engineering/main/config-files/adf-templates/web-url-ingestion.json"><code class="xref download docutils literal notranslate"><span class="pre">web-url-ingestion.json</span></code></a></p>
</div>
</div>
<div class="section" id="azure-function-app-ingestion-pipeline">
<h2>Azure Function App Ingestion Pipeline<a class="headerlink" href="#azure-function-app-ingestion-pipeline" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id17">
<h3>Metadata<a class="headerlink" href="#id17" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># -------------------------------------------------------------------------</span>
<span class="c1"># Copyright (c) 2021 NHS England and NHS Improvement. All rights reserved.</span>
<span class="c1"># Licensed under the MIT License. See license.txt in the project root for</span>
<span class="c1"># license information.</span>
<span class="c1"># -------------------------------------------------------------------------</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">FILE:           ingestion_function_app.json</span>
<span class="sd">DESCRIPTION:</span>
<span class="sd">                Pipeline to ingest raw data to Azure Datalake blob storage</span>
<span class="sd">                using an Azure function app.</span>

<span class="sd">CONTRIBUTORS:   Craig Shenton, Mattia Ficarelli</span>
<span class="sd">CONTACT:        data@nhsx.nhs.uk</span>
<span class="sd">CREATED:        29 Sept 2021</span>
<span class="sd">VERSION:        0.0.1</span>
<span class="sd">&quot;&quot;&quot;</span>
</pre></div>
</div>
</div>
<div class="section" id="id18">
<h3>Description<a class="headerlink" href="#id18" title="Permalink to this headline">¶</a></h3>
<a class="reference internal image-reference" href="_images/function_app_ingestion.png"><img alt="Data ingestion using an azure function app" src="_images/function_app_ingestion.png" style="width: 600px;" /></a>
<p><em>Figure 1: Data ingestion using an azure function app</em></p>
<p>Pipeline to ingest raw data to Azure Datalake blob storage using an Azure function app.</p>
<blockquote>
<div><ol class="arabic simple">
<li><p>Lookup the <code class="docutils literal notranslate"><span class="pre">.json</span></code> configuration file for this pipeline.</p></li>
<li><p>Set the Azure function app.</p></li>
<li><p>Azure function app activity triggers the specified function app.</p></li>
<li><p>If the Azure function app activity fails, the error notification logic app API will notify the specified email address of the error.</p></li>
</ol>
</div></blockquote>
<p>Within the Azure function app data can be saved to blob storage as either a <code class="docutils literal notranslate"><span class="pre">.csv</span></code> file or a <code class="docutils literal notranslate"><span class="pre">.parquet</span></code> file.</p>
</div>
<div class="section" id="id19">
<h3>Pipeline Configuration<a class="headerlink" href="#id19" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
  <span class="s2">&quot;pipeline&quot;</span><span class="p">:</span> <span class="p">{</span>
    <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;ingestion_function_app&quot;</span><span class="p">,</span>
    <span class="s2">&quot;folder&quot;</span><span class="p">:</span> <span class="s2">&quot;templates/ingestion/function_app&quot;</span><span class="p">,</span>
    <span class="s2">&quot;adl_file_system&quot;</span><span class="p">:</span> <span class="s2">&quot;file_system&quot;</span><span class="p">,</span>
    <span class="s2">&quot;raw&quot;</span><span class="p">:</span> <span class="p">{</span>
      <span class="s2">&quot;func_name&quot;</span><span class="p">:</span> <span class="s2">&quot;azure_func_app&quot;</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="id20">
<h3>Data Factory Configuration<a class="headerlink" href="#id20" title="Permalink to this headline">¶</a></h3>
<p>Download the Azure Data Factory <code class="docutils literal notranslate"><span class="pre">.json</span></code> configuration file to use this template in your own data pipelines.</p>
<p><a class="reference download external" download="" href="https://raw.githubusercontent.com/nhsx/au-data-engineering/main/config-files/adf-templates/function-app-ingestion.json"><code class="xref download docutils literal notranslate"><span class="pre">function-app-ingestion.json</span></code></a></p>
</div>
</div>
<div class="section" id="sharepoint-ingestion-pipeline">
<h2>SharePoint Ingestion Pipeline<a class="headerlink" href="#sharepoint-ingestion-pipeline" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id21">
<h3>Metadata<a class="headerlink" href="#id21" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># -------------------------------------------------------------------------</span>
<span class="c1"># Copyright (c) 2021 NHS England and NHS Improvement. All rights reserved.</span>
<span class="c1"># Licensed under the MIT License. See license.txt in the project root for</span>
<span class="c1"># license information.</span>
<span class="c1"># -------------------------------------------------------------------------</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">FILE:           ingestion_sharepoint.json</span>
<span class="sd">DESCRIPTION:</span>
<span class="sd">                Pipeline to ingest a specified folder and files from Microsoft</span>
<span class="sd">                SharePoint to Azure Datalake blob storage.</span>

<span class="sd">CONTRIBUTORS:   Craig Shenton, Mattia Ficarelli</span>
<span class="sd">CONTACT:        data@nhsx.nhs.uk</span>
<span class="sd">CREATED:        29 Sept 2021</span>
<span class="sd">VERSION:        0.0.1</span>
<span class="sd">&quot;&quot;&quot;</span>
</pre></div>
</div>
</div>
<div class="section" id="id22">
<h3>Description<a class="headerlink" href="#id22" title="Permalink to this headline">¶</a></h3>
<a class="reference internal image-reference" href="_images/sharepoint_ingestion.png"><img alt="Data ingestion from microsoft sharepoint" src="_images/sharepoint_ingestion.png" style="width: 600px;" /></a>
<p><em>Figure 1: Data ingestion from microsoft sharepoint</em></p>
<p>Pipeline to ingest a specified folder from Microsoft SharePoint to Azure Datalake blob storage.</p>
<blockquote>
<div><ol class="arabic simple">
<li><p>Lookup the <code class="docutils literal notranslate"><span class="pre">.json</span></code> configuration file for this pipeline.</p></li>
<li><p>Set the SharePoint file path and SharePoint logic app URL.</p></li>
<li><p>Call the SharePoint logic app using a webhook that will send back a message once the file transfer is complete.</p></li>
<li><p>If the logic app fails, the error notification logic app API will notify the specified email address of the error.</p></li>
</ol>
</div></blockquote>
</div>
<div class="section" id="id23">
<h3>Pipeline Configuration<a class="headerlink" href="#id23" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
  <span class="s2">&quot;pipeline&quot;</span><span class="p">:</span> <span class="p">{</span>
    <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;ingestion_sharepoint&quot;</span><span class="p">,</span>
    <span class="s2">&quot;folder&quot;</span><span class="p">:</span> <span class="s2">&quot;templates/ingestion/sharepoint&quot;</span><span class="p">,</span>
    <span class="s2">&quot;adl_file_system&quot;</span><span class="p">:</span> <span class="s2">&quot;file_system&quot;</span><span class="p">,</span>
    <span class="s2">&quot;raw&quot;</span><span class="p">:</span> <span class="p">{</span>
      <span class="s2">&quot;source_path&quot;</span><span class="p">:</span> <span class="s2">&quot;...sharepoint/...&quot;</span><span class="p">,</span>
      <span class="s2">&quot;logic_app_url&quot;</span><span class="p">:</span> <span class="s2">&quot;https://...logic.azure.com/...&quot;</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="id24">
<h3>Data Factory Configuration<a class="headerlink" href="#id24" title="Permalink to this headline">¶</a></h3>
<p>Download the Azure Data Factory <code class="docutils literal notranslate"><span class="pre">.json</span></code> configuration file to use this template in your own data pipelines.</p>
<p><a class="reference download external" download="" href="https://raw.githubusercontent.com/nhsx/au-data-engineering/main/config-files/adf-templates/sharepoint-ingestion.json"><code class="xref download docutils literal notranslate"><span class="pre">sharepoint-ingestion.json</span></code></a></p>
</div>
</div>
<div class="section" id="databricks-processing-pipeline">
<h2>Databricks Processing Pipeline<a class="headerlink" href="#databricks-processing-pipeline" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id25">
<h3>Metadata<a class="headerlink" href="#id25" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># -------------------------------------------------------------------------</span>
<span class="c1"># Copyright (c) 2021 NHS England and NHS Improvement. All rights reserved.</span>
<span class="c1"># Licensed under the MIT License. See license.txt in the project root for</span>
<span class="c1"># license information.</span>
<span class="c1"># -------------------------------------------------------------------------</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">FILE:           processing_databricks.json</span>
<span class="sd">DESCRIPTION:</span>
<span class="sd">                Pipeline to process data from a folder in Azure Datalake</span>
<span class="sd">                blob storage using a databricks notebook.</span>

<span class="sd">CONTRIBUTORS:   Craig Shenton, Mattia Ficarelli</span>
<span class="sd">CONTACT:        data@nhsx.nhs.uk</span>
<span class="sd">CREATED:        23 Sept 2021</span>
<span class="sd">VERSION:        0.0.1</span>
<span class="sd">&quot;&quot;&quot;</span>
</pre></div>
</div>
</div>
<div class="section" id="id26">
<h3>Description<a class="headerlink" href="#id26" title="Permalink to this headline">¶</a></h3>
<a class="reference internal image-reference" href="_images/databricks.png"><img alt="Data processing using a Databricks notebook" src="_images/databricks.png" style="width: 600px;" /></a>
<p><em>Figure 1: Data processing using a Databricks notebook</em></p>
<p>Pipeline to process data from a folder in Azure Datalake blob storage using a databricks notebook</p>
<blockquote>
<div><ol class="arabic simple">
<li><p>Lookup the <code class="docutils literal notranslate"><span class="pre">.json</span></code> configuration file for this pipeline.</p></li>
<li><p>Set the databricks notebook path.</p></li>
<li><p>Databricks notebook activity runs the databricks notebook specified using an ephemeral job cluster.</p></li>
<li><p>If the databricks notebook activity fails, the error notification logic app API will notify the specified email address of the error.</p></li>
</ol>
</div></blockquote>
</div>
<div class="section" id="id27">
<h3>Pipeline Configuration<a class="headerlink" href="#id27" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
  <span class="s2">&quot;pipeline&quot;</span><span class="p">:</span> <span class="p">{</span>
    <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;processing_databricks&quot;</span><span class="p">,</span>
    <span class="s2">&quot;folder&quot;</span><span class="p">:</span> <span class="s2">&quot;templates/processing/databricks&quot;</span><span class="p">,</span>
    <span class="s2">&quot;project&quot;</span><span class="p">:</span> <span class="p">{</span>
      <span class="s2">&quot;databricks_notebook&quot;</span><span class="p">:</span> <span class="s2">&quot;/path/to/databricks/notebook&quot;</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="databricks-orchestration">
<h3>Databricks Orchestration<a class="headerlink" href="#databricks-orchestration" title="Permalink to this headline">¶</a></h3>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Alternatively this pipeline can be used to trigger an orchestrator databricks notebook which in turn runs a series of data processing notebooks.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
  <span class="s2">&quot;pipeline&quot;</span><span class="p">:</span> <span class="p">{</span>
    <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;processing_databricks&quot;</span><span class="p">,</span>
    <span class="s2">&quot;folder&quot;</span><span class="p">:</span> <span class="s2">&quot;templates/processing/databricks_orchestrator&quot;</span><span class="p">,</span>
    <span class="s2">&quot;project&quot;</span><span class="p">:</span> <span class="p">{</span>
      <span class="s2">&quot;databricks_orchestrator_notebook&quot;</span><span class="p">:</span> <span class="s2">&quot;/path/to/databricks/orchestrator_notebook&quot;</span>
      <span class="s2">&quot;databricks&quot;</span><span class="p">:[</span>
          <span class="p">{</span>
        <span class="s2">&quot;sink_path&quot;</span><span class="p">:</span> <span class="s2">&quot;path/to/processed/data&quot;</span><span class="p">,</span>
        <span class="s2">&quot;sink_file&quot;</span><span class="p">:</span> <span class="s2">&quot;file_1.csv&quot;</span><span class="p">,</span>
        <span class="s2">&quot;databricks_notebook&quot;</span><span class="p">:</span> <span class="s2">&quot;/path/to/databricks/processing_notebook1&quot;</span>
        <span class="p">},</span>
          <span class="p">{</span>
        <span class="s2">&quot;sink_path&quot;</span><span class="p">:</span> <span class="s2">&quot;path/to/processed/data&quot;</span><span class="p">,</span>
        <span class="s2">&quot;sink_file&quot;</span><span class="p">:</span> <span class="s2">&quot;file_2.csv&quot;</span><span class="p">,</span>
        <span class="s2">&quot;databricks_notebook&quot;</span><span class="p">:</span> <span class="s2">&quot;/path/to/databricks/processing_notebook2&quot;</span>
        <span class="p">},</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Python code to sequentially run databricks notebook paths specified in a <code class="docutils literal notranslate"><span class="pre">.json</span></code> config file from a databricks orchestrator notebook.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">#Squentially run datbricks notebooks</span>
<span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">item</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">config_JSON</span><span class="p">[</span><span class="s1">&#39;pipeline&#39;</span><span class="p">][</span><span class="s1">&#39;project&#39;</span><span class="p">][</span><span class="s1">&#39;databricks&#39;</span><span class="p">]):</span>
    <span class="n">notebook</span> <span class="o">=</span> <span class="n">config_JSON</span><span class="p">[</span><span class="s1">&#39;pipeline&#39;</span><span class="p">][</span><span class="s1">&#39;project&#39;</span><span class="p">][</span><span class="s1">&#39;databricks&#39;</span><span class="p">][</span><span class="n">index</span><span class="p">][</span><span class="s1">&#39;databricks_notebook&#39;</span><span class="p">]</span>
    <span class="n">dbutils</span><span class="o">.</span><span class="n">notebook</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">notebook</span><span class="p">,</span> <span class="mi">120</span><span class="p">)</span>
  <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="id28">
<h3>Data Factory Configuration<a class="headerlink" href="#id28" title="Permalink to this headline">¶</a></h3>
<p>Download the Azure Data Factory <code class="docutils literal notranslate"><span class="pre">.json</span></code> configuration file to use this template in your own data pipelines.</p>
<p><a class="reference download external" download="" href="https://raw.githubusercontent.com/nhsx/au-data-engineering/main/config-files/adf-templates/databricks-processing.json"><code class="xref download docutils literal notranslate"><span class="pre">processing-databricks.json</span></code></a></p>
</div>
</div>
<div class="section" id="azure-function-app-processing-pipeline">
<h2>Azure Function App Processing Pipeline<a class="headerlink" href="#azure-function-app-processing-pipeline" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id29">
<h3>Metadata<a class="headerlink" href="#id29" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># -------------------------------------------------------------------------</span>
<span class="c1"># Copyright (c) 2021 NHS England and NHS Improvement. All rights reserved.</span>
<span class="c1"># Licensed under the MIT License. See license.txt in the project root for</span>
<span class="c1"># license information.</span>
<span class="c1"># -------------------------------------------------------------------------</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">FILE:           processing_function_app.json</span>
<span class="sd">DESCRIPTION:</span>
<span class="sd">                Pipeline to process data to time-stamped folder in</span>
<span class="sd">                Azure Datalake blob storage using an Azure function app.</span>

<span class="sd">CONTRIBUTORS:   Craig Shenton, Mattia Ficarelli</span>
<span class="sd">CONTACT:        data@nhsx.nhs.uk</span>
<span class="sd">CREATED:        29 Sept 2021</span>
<span class="sd">VERSION:        0.0.1</span>
<span class="sd">&quot;&quot;&quot;</span>
</pre></div>
</div>
</div>
<div class="section" id="id30">
<h3>Description<a class="headerlink" href="#id30" title="Permalink to this headline">¶</a></h3>
<a class="reference internal image-reference" href="_images/function_app_processing.png"><img alt="Data processing using an azure function app" src="_images/function_app_processing.png" style="width: 600px;" /></a>
<p><em>Figure 1: Data processing using an azure function app</em></p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This pipeline is designed to allow for raw data to be ingested and then appended onto an existing table with historical data.</p>
</div>
<p>Pipeline to process data to time-stamped folder in Azure Datalake blob storage using an Azure function app.</p>
<blockquote>
<div><ol class="arabic simple">
<li><p>Lookup the <code class="docutils literal notranslate"><span class="pre">.json</span></code> configuration file for this pipeline.</p></li>
<li><p>Set the source path (of the data to be processed).</p></li>
<li><p>Set the file system.</p></li>
<li><p>Set the Azure function app.</p></li>
<li><p>Use the ‘laterFolder’ utility to find and save the latest folder in the source path.</p></li>
<li><p>If the ‘laterFolder’ utility fails, the error notification logic app API will notify the specified email address of the error.</p></li>
<li><p>Lookup the latest folder.</p></li>
<li><p>Set the latest folder.</p></li>
<li><p>Set the <code class="docutils literal notranslate"><span class="pre">.json</span></code> body for the Azure function app.</p></li>
<li><p>Run the Azure function app activity.</p></li>
<li><p>If the Azure function app activity fails, the error notification logic app API will notify the specified email address of the error.</p></li>
</ol>
</div></blockquote>
<p>Within the Azure function app data can be saved to blob storage as either a <code class="docutils literal notranslate"><span class="pre">.csv</span></code> file or a <code class="docutils literal notranslate"><span class="pre">.parquet</span></code> file.</p>
</div>
<div class="section" id="id31">
<h3>Pipeline Configuration<a class="headerlink" href="#id31" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
  <span class="s2">&quot;pipeline&quot;</span><span class="p">:</span> <span class="p">{</span>
    <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;processing_function_app&quot;</span><span class="p">,</span>
    <span class="s2">&quot;folder&quot;</span><span class="p">:</span> <span class="s2">&quot;templates/processing/function_app&quot;</span><span class="p">,</span>
    <span class="s2">&quot;adl_file_system&quot;</span><span class="p">:</span> <span class="s2">&quot;file_system&quot;</span><span class="p">,</span>
    <span class="s2">&quot;project&quot;</span><span class="p">:</span> <span class="p">{</span>
      <span class="s2">&quot;func_name&quot;</span><span class="p">:</span> <span class="s2">&quot;azure_func_app&quot;</span><span class="p">,</span>
      <span class="s2">&quot;source_path&quot;</span><span class="p">:</span> <span class="s2">&quot;raw/historical/data/source&quot;</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="id32">
<h3>Data Factory Configuration<a class="headerlink" href="#id32" title="Permalink to this headline">¶</a></h3>
<p>Download the Azure Data Factory <code class="docutils literal notranslate"><span class="pre">.json</span></code> configuration file to use this template in your own data pipelines.</p>
<p><a class="reference download external" download="" href="https://raw.githubusercontent.com/nhsx/au-data-engineering/main/config-files/adf-templates/function-app-processing.json"><code class="xref download docutils literal notranslate"><span class="pre">function-app-processing.json</span></code></a></p>
</div>
</div>
<div class="section" id="multiple-azure-function-apps-processing-pipeline">
<h2>Multiple Azure Function Apps Processing Pipeline<a class="headerlink" href="#multiple-azure-function-apps-processing-pipeline" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id33">
<h3>Metadata<a class="headerlink" href="#id33" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># -------------------------------------------------------------------------</span>
<span class="c1"># Copyright (c) 2021 NHS England and NHS Improvement. All rights reserved.</span>
<span class="c1"># Licensed under the MIT License. See license.txt in the project root for</span>
<span class="c1"># license information.</span>
<span class="c1"># -------------------------------------------------------------------------</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">FILE:           processing_multiple_function_apps.json</span>
<span class="sd">DESCRIPTION:</span>
<span class="sd">                Pipeline to process data to time-stamped folders in</span>
<span class="sd">                Azure Datalake blob storage using multiple Azure function apps.</span>

<span class="sd">CONTRIBUTORS:   Craig Shenton, Mattia Ficarelli</span>
<span class="sd">CONTACT:        data@nhsx.nhs.uk</span>
<span class="sd">CREATED:        29 Sept 2021</span>
<span class="sd">VERSION:        0.0.1</span>
<span class="sd">&quot;&quot;&quot;</span>
</pre></div>
</div>
</div>
<div class="section" id="id34">
<h3>Description<a class="headerlink" href="#id34" title="Permalink to this headline">¶</a></h3>
<a class="reference internal image-reference" href="_images/multiple_function_app_processing.png"><img alt="Data processing using multiple azure function apps" src="_images/multiple_function_app_processing.png" style="width: 600px;" /></a>
<p><em>Figure 1: Data processing using multiple azure function apps</em></p>
<a class="reference internal image-reference" href="_images/multiple_function_app_processing_2.png"><img alt="ForEach loop activities within pipeline" src="_images/multiple_function_app_processing_2.png" style="width: 600px;" /></a>
<p><em>Figure 2: ForEach loop activities within pipeline</em></p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This pipeline allows for multiple different processed data files to be generated from the same data source during a pipeline run by using multiple function apps running sequentially.</p>
</div>
<p>Pipeline to process data to time-stamped folder in Azure Datalake blob storage using multiple Azure function apps.</p>
<blockquote>
<div><ol class="arabic simple">
<li><p>Lookup the <code class="docutils literal notranslate"><span class="pre">.json</span></code> configuration file for this pipeline.</p></li>
<li><p>Set the source path (of the data to be processed).</p></li>
<li><p>Set the file system.</p></li>
<li><p>Set the Azure function app.</p></li>
<li><p>Use the ‘laterFolder’ utility to find and save the latest folder in the source path.</p></li>
<li><p>If the ‘laterFolder’ utility fails, the error notification logic app API will notify the specified email address of the error.</p></li>
<li><p>Lookup the latest folder.</p></li>
<li><p>Set the latest folder.</p></li>
<li><p>Set the <code class="docutils literal notranslate"><span class="pre">.json</span></code> body for the Azure function app.</p></li>
<li><p>Set an <code class="docutils literal notranslate"><span class="pre">array</span></code> variable containing the list of Azure function apps to be run.</p></li>
<li><p>ForEach loops over each azure function:</p></li>
</ol>
<blockquote>
<div><ol class="loweralpha simple">
<li><p>Runs the Azure function app activity.</p></li>
<li><p>If the Azure function app activity fails, the error notification logic app API will notify the specified email address of the error.</p></li>
</ol>
</div></blockquote>
</div></blockquote>
<p>Within the Azure function app data can be saved to blob storage as either a <code class="docutils literal notranslate"><span class="pre">.csv</span></code> file or a <code class="docutils literal notranslate"><span class="pre">.parquet</span></code> file.</p>
</div>
<div class="section" id="id35">
<h3>Pipeline Configuration<a class="headerlink" href="#id35" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
  <span class="s2">&quot;pipeline&quot;</span><span class="p">:</span> <span class="p">{</span>
    <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;processing_function_app&quot;</span><span class="p">,</span>
    <span class="s2">&quot;folder&quot;</span><span class="p">:</span> <span class="s2">&quot;templates/processing/function_app&quot;</span><span class="p">,</span>
    <span class="s2">&quot;adl_file_system&quot;</span><span class="p">:</span> <span class="s2">&quot;file_system&quot;</span><span class="p">,</span>
    <span class="s2">&quot;project&quot;</span><span class="p">:</span> <span class="p">{</span>
      <span class="s2">&quot;functions&quot;</span><span class="p">:</span> <span class="p">[</span>
        <span class="p">{</span><span class="s2">&quot;func_name&quot;</span><span class="p">:</span> <span class="s2">&quot;azure_func_app_1&quot;</span><span class="p">},</span>
        <span class="p">{</span><span class="s2">&quot;func_name&quot;</span><span class="p">:</span> <span class="s2">&quot;azure_func_app_2&quot;</span><span class="p">},</span>
        <span class="p">{</span><span class="s2">&quot;func_name&quot;</span><span class="p">:</span> <span class="s2">&quot;azure_func_app_3&quot;</span><span class="p">}</span>
                        <span class="p">],</span>
      <span class="s2">&quot;source_path&quot;</span><span class="p">:</span> <span class="s2">&quot;raw/historical/data/source&quot;</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="id36">
<h3>Data Factory Configuration<a class="headerlink" href="#id36" title="Permalink to this headline">¶</a></h3>
<p>Download the Azure Data Factory <code class="docutils literal notranslate"><span class="pre">.json</span></code> configuration file to use this template in your own data pipelines.</p>
<p><a class="reference download external" download="" href="https://raw.githubusercontent.com/nhsx/au-data-engineering/main/config-files/adf-templates/multiple-function-app-processing.json"><code class="xref download docutils literal notranslate"><span class="pre">multiple-function-app-processing.json</span></code></a></p>
</div>
</div>
<div class="section" id="copy-file-processing-pipeline">
<h2>Copy File Processing Pipeline<a class="headerlink" href="#copy-file-processing-pipeline" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id37">
<h3>Metadata<a class="headerlink" href="#id37" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># -------------------------------------------------------------------------</span>
<span class="c1"># Copyright (c) 2021 NHS England and NHS Improvement. All rights reserved.</span>
<span class="c1"># Licensed under the MIT License. See license.txt in the project root for</span>
<span class="c1"># license information.</span>
<span class="c1"># -------------------------------------------------------------------------</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">FILE:           processing_csv_file.json</span>
<span class="sd">DESCRIPTION:</span>
<span class="sd">                Pipeline to copy a .csv file in a time-stamped folder</span>
<span class="sd">                between directories in Azure Datalake blob storage.</span>

<span class="sd">CONTRIBUTORS:   Craig Shenton, Mattia Ficarelli</span>
<span class="sd">CONTACT:        data@nhsx.nhs.uk</span>
<span class="sd">CREATED:        29 Sept 2021</span>
<span class="sd">VERSION:        0.0.1</span>
<span class="sd">&quot;&quot;&quot;</span>
</pre></div>
</div>
</div>
<div class="section" id="id38">
<h3>Description<a class="headerlink" href="#id38" title="Permalink to this headline">¶</a></h3>
<a class="reference internal image-reference" href="_images/csv_file_processing.png"><img alt="Copying a .csv file between Azure Datalake directories" src="_images/csv_file_processing.png" style="width: 600px;" /></a>
<p><em>Figure 1: Copying a ``.csv`` file between Azure Datalake directories</em></p>
<p>Pipeline to copy a <code class="docutils literal notranslate"><span class="pre">.csv</span></code> file in a time-stamped folder between directories in Azure Datalake blob storage.</p>
<blockquote>
<div><ol class="arabic simple">
<li><p>Lookup the <code class="docutils literal notranslate"><span class="pre">.json</span></code> configuration file for this pipeline.</p></li>
<li><p>Set the Azure Datalake file system</p></li>
<li><p>Set the source path and source file name.</p></li>
<li><p>Set the sink path and sink file name.</p></li>
<li><p>Use the ‘laterFolder’ utility to find and save the latest folder in the source path.</p></li>
<li><p>If the ‘laterFolder’ utility fails, the error notification logic app API will notify the specified email address of the error.</p></li>
<li><p>Lookup the latest folder.</p></li>
<li><p>Set the latest folder.</p></li>
<li><p>Copy activity copies the <code class="docutils literal notranslate"><span class="pre">.csv</span></code> file between the Datalake directories.</p></li>
<li><p>If the copy activity fails, the error notification logic app API will notify the specified email address of the error.</p></li>
</ol>
</div></blockquote>
</div>
<div class="section" id="id39">
<h3>Pipeline Configuration<a class="headerlink" href="#id39" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
  <span class="s2">&quot;pipeline&quot;</span><span class="p">:</span> <span class="p">{</span>
    <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;processing_csv_file&quot;</span><span class="p">,</span>
    <span class="s2">&quot;folder&quot;</span><span class="p">:</span> <span class="s2">&quot;templates/processing/csv_file&quot;</span><span class="p">,</span>
    <span class="s2">&quot;adl_file_system&quot;</span><span class="p">:</span> <span class="s2">&quot;file_system&quot;</span><span class="p">,</span>
    <span class="s2">&quot;project&quot;</span><span class="p">:</span> <span class="p">{</span>
      <span class="s2">&quot;source_path&quot;</span><span class="p">:</span> <span class="s2">&quot;raw/&quot;</span><span class="p">,</span>
      <span class="s2">&quot;source_name&quot;</span><span class="p">:</span> <span class="s2">&quot;file.csv&quot;</span><span class="p">,</span>
      <span class="s2">&quot;sink_path&quot;</span><span class="p">:</span> <span class="s2">&quot;proc/&quot;</span><span class="p">,</span>
      <span class="s2">&quot;sink_name&quot;</span><span class="p">:</span> <span class="s2">&quot;file_copy.csv&quot;</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="id40">
<h3>Data Factory Configuration<a class="headerlink" href="#id40" title="Permalink to this headline">¶</a></h3>
<p>Download the Azure Data Factory <code class="docutils literal notranslate"><span class="pre">.json</span></code> configuration file to use this template in your own data pipelines.</p>
<p><a class="reference download external" download="" href="https://raw.githubusercontent.com/nhsx/au-data-engineering/main/config-files/adf-templates/csv-file-processing.json"><code class="xref download docutils literal notranslate"><span class="pre">csv-file-processing.json</span></code></a></p>
</div>
</div>
<div class="section" id="sql-table-staging-pipeline">
<h2>SQL Table Staging Pipeline<a class="headerlink" href="#sql-table-staging-pipeline" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id41">
<h3>Metadata<a class="headerlink" href="#id41" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># -------------------------------------------------------------------------</span>
<span class="c1"># Copyright (c) 2021 NHS England and NHS Improvement. All rights reserved.</span>
<span class="c1"># Licensed under the MIT License. See license.txt in the project root for</span>
<span class="c1"># license information.</span>
<span class="c1"># -------------------------------------------------------------------------</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">FILE:           staging_sql_database.json</span>
<span class="sd">DESCRIPTION:</span>
<span class="sd">                Pipeline to stage data from a time-stamped folder in</span>
<span class="sd">                Azure Datalake blob storage to a table in an Azure SQL database.</span>

<span class="sd">CONTRIBUTORS:   Craig Shenton, Mattia Ficarelli</span>
<span class="sd">CONTACT:        data@nhsx.nhs.uk</span>
<span class="sd">CREATED:        29 Sept 2021</span>
<span class="sd">VERSION:        0.0.1</span>
<span class="sd">&quot;&quot;&quot;</span>
</pre></div>
</div>
</div>
<div class="section" id="id42">
<h3>Description<a class="headerlink" href="#id42" title="Permalink to this headline">¶</a></h3>
<a class="reference internal image-reference" href="_images/sql_database_staging.png"><img alt="Data staging to a table in an Azure SQL database" src="_images/sql_database_staging.png" style="width: 600px;" /></a>
<p><em>Figure 1: Data staging to a table in an Azure SQL database</em></p>
<p>Pipeline to stage data (<code class="docutils literal notranslate"><span class="pre">.csv</span></code> file) from a time-stamped folder in Azure Datalake blob storage to a table in an Azure SQL database.</p>
<blockquote>
<div><ol class="arabic simple">
<li><p>Lookup the <code class="docutils literal notranslate"><span class="pre">.json</span></code> configuration file for this pipeline.</p></li>
<li><p>Set the source path (of data to be staged).</p></li>
<li><p>Set the source file.</p></li>
<li><p>Set the file system.</p></li>
<li><p>Set the sink table (target table in the SQL database).</p></li>
<li><p>Set the stored procedure (truncates data in the target table in the SQL database).</p></li>
<li><p>Run the stored procedure activity. The stored procedure also sets the data type of each column in the database table.</p></li>
<li><p>Use the ‘laterFolder’ utility to find and save the latest folder in the source path.</p></li>
<li><p>If the ‘laterFolder’ utility fails, the error notification logic app API will notify the specified email address of the error.</p></li>
<li><p>Lookup the latest folder.</p></li>
<li><p>Set the latest folder.</p></li>
<li><p>Run the copy activity which stages data from a <code class="docutils literal notranslate"><span class="pre">.csv</span></code> file in Azure Datalake blob storage to an empty table in an Azure SQL database.</p></li>
<li><p>If the Azure copy activity fails, the error notification logic app API will notify the specified email address of the error.</p></li>
</ol>
</div></blockquote>
</div>
<div class="section" id="id43">
<h3>Pipeline Configuration<a class="headerlink" href="#id43" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
  <span class="s2">&quot;pipeline&quot;</span><span class="p">:</span> <span class="p">{</span>
    <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;staging_sql_database&quot;</span><span class="p">,</span>
    <span class="s2">&quot;folder&quot;</span><span class="p">:</span> <span class="s2">&quot;templates/staging/sql_database&quot;</span><span class="p">,</span>
    <span class="s2">&quot;adl_file_system&quot;</span><span class="p">:</span> <span class="s2">&quot;file_system&quot;</span><span class="p">,</span>
    <span class="s2">&quot;staging&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;stored_procedure&quot;</span><span class="p">:</span><span class="s2">&quot;[dbo].[sql_stored_procedure_table_1]&quot;</span><span class="p">,</span>
        <span class="s2">&quot;source_path&quot;</span><span class="p">:</span><span class="s2">&quot;proc/projects/path/to/processed/data/&quot;</span><span class="p">,</span>
        <span class="s2">&quot;source_file&quot;</span><span class="p">:</span><span class="s2">&quot;table_1.csv&quot;</span><span class="p">,</span>
        <span class="s2">&quot;sink_table&quot;</span><span class="p">:</span><span class="s2">&quot;sql_table_1&quot;</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="id44">
<h3>Data Factory Configuration<a class="headerlink" href="#id44" title="Permalink to this headline">¶</a></h3>
<p>Download the Azure Data Factory <code class="docutils literal notranslate"><span class="pre">.json</span></code> configuration file to use this template in your own data pipelines.</p>
<p><a class="reference download external" download="" href="https://raw.githubusercontent.com/nhsx/au-data-engineering/main/config-files/adf-templates/staging-sql-database.json"><code class="xref download docutils literal notranslate"><span class="pre">sql-database-staging.json</span></code></a></p>
</div>
</div>
<div class="section" id="multiple-sql-table-staging-pipeline">
<h2>Multiple SQL Table Staging Pipeline<a class="headerlink" href="#multiple-sql-table-staging-pipeline" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id45">
<h3>Metadata<a class="headerlink" href="#id45" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># -------------------------------------------------------------------------</span>
<span class="c1"># Copyright (c) 2021 NHS England and NHS Improvement. All rights reserved.</span>
<span class="c1"># Licensed under the MIT License. See license.txt in the project root for</span>
<span class="c1"># license information.</span>
<span class="c1"># -------------------------------------------------------------------------</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">FILE:           multiple_tables_staging_sql_database.json</span>
<span class="sd">DESCRIPTION:</span>
<span class="sd">                Pipeline to stage data from a time-stamped folders in</span>
<span class="sd">                Azure Datalake blob storage to multiple tables in an Azure SQL database.</span>

<span class="sd">CONTRIBUTORS:   Craig Shenton, Mattia Ficarelli</span>
<span class="sd">CONTACT:        data@nhsx.nhs.uk</span>
<span class="sd">CREATED:        29 Sept 2021</span>
<span class="sd">VERSION:        0.0.1</span>
<span class="sd">&quot;&quot;&quot;</span>
</pre></div>
</div>
</div>
<div class="section" id="id46">
<h3>Description<a class="headerlink" href="#id46" title="Permalink to this headline">¶</a></h3>
<a class="reference internal image-reference" href="_images/multiple_table_sql_database_staging.png"><img alt="Data staging to multiple tables in an Azure SQL database" src="_images/multiple_table_sql_database_staging.png" style="width: 600px;" /></a>
<p><em>Figure 1: Data staging to multiple tables in an Azure SQL database</em></p>
<a class="reference internal image-reference" href="_images/multiple_table_sql_database_staging_2.png"><img alt="ForEach loop activities within pipeline" src="_images/multiple_table_sql_database_staging_2.png" style="width: 600px;" /></a>
<p><em>Figure 2: ForEach loop activities within pipeline</em></p>
<p>Pipeline to stage data (<code class="docutils literal notranslate"><span class="pre">.csv</span></code> files) from a time-stamped folders in Azure Datalake blob storage to multiple tables in an Azure SQL database.</p>
<blockquote>
<div><ol class="arabic simple">
<li><p>Lookup the <code class="docutils literal notranslate"><span class="pre">.json</span></code> configuration file for this pipeline.</p></li>
<li><p>Set the file system.</p></li>
<li><p>Set an <code class="docutils literal notranslate"><span class="pre">array</span></code> variable containing the list of stored procedures and tables to which processed data is to be staged.</p></li>
<li><p>For each element in the list the ForEach loop:</p>
<ol class="loweralpha simple">
<li><p>Sets the source path (of data to be staged).</p></li>
<li><p>Sets the source file.</p></li>
<li><p>Uses the ‘laterFolder’ utility to find and save the latest folder in the source path.</p></li>
<li><p>Lookups the latest folder.</p></li>
<li><p>Sets the latest folder.</p></li>
<li><p>Sets the sink table (target table in the SQL database).</p></li>
<li><p>Sets the stored procedure (truncates data in the target table in the SQL database).</p></li>
<li><p>Runs the stored procedure activity. The stored procedure also sets the data type of each column in the database table.</p></li>
<li><p>Runs the copy activity which stages data from a <code class="docutils literal notranslate"><span class="pre">.csv</span></code> file in azure Datalake blob storage to an empty table in an Azure SQL database.</p></li>
<li><p>If the Azure copy activity fails, the error notification logic app API will notify the specified email address of the error.</p></li>
</ol>
</li>
</ol>
</div></blockquote>
</div>
<div class="section" id="id47">
<h3>Pipeline Configuration<a class="headerlink" href="#id47" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
  <span class="s2">&quot;pipeline&quot;</span><span class="p">:</span> <span class="p">{</span>
    <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;multiple_tables_staging_sql_database&quot;</span><span class="p">,</span>
    <span class="s2">&quot;folder&quot;</span><span class="p">:</span> <span class="s2">&quot;templates/staging/multiple_tables_sql_database&quot;</span><span class="p">,</span>
    <span class="s2">&quot;adl_file_system&quot;</span><span class="p">:</span> <span class="s2">&quot;file_system&quot;</span><span class="p">,</span>
    <span class="s2">&quot;staging&quot;</span><span class="p">:</span> <span class="p">[</span>
          <span class="p">{</span>
            <span class="s2">&quot;stored_procedure&quot;</span><span class="p">:</span><span class="s2">&quot;[dbo].[sql_stored_procedure_table_1]&quot;</span><span class="p">,</span>
            <span class="s2">&quot;source_path&quot;</span><span class="p">:</span><span class="s2">&quot;proc/projects/path/to/processed/data/&quot;</span><span class="p">,</span>
            <span class="s2">&quot;source_file&quot;</span><span class="p">:</span><span class="s2">&quot;table_1.csv&quot;</span><span class="p">,</span>
            <span class="s2">&quot;sink_table&quot;</span><span class="p">:</span><span class="s2">&quot;sql_table_1&quot;</span>
          <span class="p">},</span>
          <span class="p">{</span>
            <span class="s2">&quot;stored_procedure&quot;</span><span class="p">:</span><span class="s2">&quot;[dbo].[sql_stored_procedure_table_2]&quot;</span><span class="p">,</span>
            <span class="s2">&quot;source_path&quot;</span><span class="p">:</span><span class="s2">&quot;proc/projects/path/to/processed/data2/&quot;</span><span class="p">,</span>
            <span class="s2">&quot;source_file&quot;</span><span class="p">:</span><span class="s2">&quot;table_2.csv&quot;</span><span class="p">,</span>
            <span class="s2">&quot;sink_table&quot;</span><span class="p">:</span><span class="s2">&quot;sql_table_2&quot;</span>
          <span class="p">},</span>
          <span class="p">{</span>
            <span class="s2">&quot;stored_procedure&quot;</span><span class="p">:</span><span class="s2">&quot;[dbo].[sql_stored_procedure_table_3]&quot;</span><span class="p">,</span>
            <span class="s2">&quot;source_path&quot;</span><span class="p">:</span><span class="s2">&quot;proc/projects/path/to/processed/data3/&quot;</span><span class="p">,</span>
            <span class="s2">&quot;source_file&quot;</span><span class="p">:</span><span class="s2">&quot;table_3.csv&quot;</span><span class="p">,</span>
            <span class="s2">&quot;sink_table&quot;</span><span class="p">:</span><span class="s2">&quot;sql_table_3&quot;</span>
          <span class="p">}</span>
      <span class="p">]</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="id48">
<h3>Data Factory Configuration<a class="headerlink" href="#id48" title="Permalink to this headline">¶</a></h3>
<p>Download the Azure Data Factory <code class="docutils literal notranslate"><span class="pre">.json</span></code> configuration file to use this template in your own data pipelines.</p>
<p><a class="reference download external" download="" href="https://raw.githubusercontent.com/nhsx/au-data-engineering/main/config-files/adf-templates/multiple-tables-sql-database-staging.json"><code class="xref download docutils literal notranslate"><span class="pre">multiple-tables-sql-database-staging.json</span></code></a></p>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="adfutilities.html" class="btn btn-neutral float-right" title="Azure Data Factory Utilities" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="readme.html" class="btn btn-neutral float-left" title="Azure Platform Overview" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2021 NHS England and NHS Improvement, MIT Licence.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>